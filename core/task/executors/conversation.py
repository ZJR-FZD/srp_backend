# core/task/executors/conversation.py
"""ConversationExecutor - æ™ºèƒ½å¯¹è¯ä»»åŠ¡æ‰§è¡Œå™¨"""

from typing import TYPE_CHECKING, Dict, Any
from core.task.executors.base import BaseTaskExecutor
from core.task.models import UnifiedTask, TaskStatus, TaskType
import asyncio

if TYPE_CHECKING:
    from core.agent import RobotAgent


class ConversationExecutor(BaseTaskExecutor):
    """æ™ºèƒ½å¯¹è¯æ‰§è¡Œå™¨
    
    æµç¨‹ï¼š
    1. æ¥æ”¶ç”¨æˆ·è¯­éŸ³æ–‡æœ¬
    2. æ„å›¾åˆ†æï¼ˆæ˜¯å¦éœ€è¦ MCP å·¥å…·ï¼Ÿï¼‰
    3. å¦‚éœ€å·¥å…· â†’ åˆ›å»º MCP_CALL ä»»åŠ¡å¹¶ç­‰å¾…
    4. LLM ç”Ÿæˆå›å¤
    5. è¯­éŸ³æ’­æŠ¥
    """
    
    def __init__(self, agent: 'RobotAgent', llm_client):
        super().__init__()
        self.agent = agent
        self.llm_client = llm_client
        self.conversation_history = []
        self.max_history_length = 10
    
    async def validate(self, task: UnifiedTask) -> bool:
        if not await super().validate(task):
            return False
        
        user_text = task.execution_data.get("user_text")
        if not user_text:
            self._log(task, "No user_text provided", "ERROR")
            return False
        
        return True
    
    async def execute(self, task: UnifiedTask) -> None:
        """æ‰§è¡Œå¯¹è¯ä»»åŠ¡"""
        try:
            if not await self.validate(task):
                task.transition_to(TaskStatus.FAILED, "Validation failed")
                return
            
            user_text = task.execution_data.get("user_text")
            self._log(task, f"User: {user_text}")
            
            # 1. æ„å›¾åˆ†æ
            intent_result = await self._analyze_intent(user_text)
            
            intent_type = intent_result.get("intent_type")
            response_text = intent_result.get("response", "")
            task_info = intent_result.get("task_info")
            
            # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ MCP å·¥å…·
            if intent_type == "task_request" and task_info:
                executor_type = task_info.get("executor_type")
                
                if executor_type == "mcp":
                    self._log(task, "Calling MCP tool...")
                    
                    # åˆ›å»º MCP ä»»åŠ¡å¹¶ç­‰å¾…
                    mcp_result = await self._call_mcp_tool(task_info)
                    
                    if mcp_result.get("success"):
                        # èåˆ MCP ç»“æœç”Ÿæˆå›å¤
                        response_text = await self._generate_final_response(
                            user_text, 
                            mcp_result
                        )
                    else:
                        response_text = f"æŠ±æ­‰ï¼Œæ‰§è¡Œä»»åŠ¡æ—¶å‡ºé”™äº†ï¼š{mcp_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            # 3. è¯­éŸ³æ’­æŠ¥
            self._log(task, f"Bot: {response_text}")
            await self._speak(response_text)
            
            # 4. æ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": user_text})
            self.conversation_history.append({"role": "assistant", "content": response_text})
            
            if len(self.conversation_history) > self.max_history_length * 2:
                self.conversation_history = self.conversation_history[-self.max_history_length:]
            
            # 5. ä»»åŠ¡å®Œæˆ
            task.result = {
                "success": True,
                "user_input": user_text,
                "bot_response": response_text,
                "used_mcp": executor_type == "mcp" if task_info else False
            }
            
            task.transition_to(TaskStatus.COMPLETED, "Conversation completed")
            
        except Exception as e:
            await self.handle_error(task, e)
    
    async def _analyze_intent(self, user_text: str) -> Dict[str, Any]:
        """æ„å›¾åˆ†æ"""
        from config import build_analyze_prompt
        
        # è·å– MCP å·¥å…·åˆ—è¡¨
        mcp_tools = []
        if hasattr(self.agent, 'mcp_manager') and self.agent.mcp_manager:
            all_tools = self.agent.mcp_manager.tool_index.get_all_tools()
            mcp_tools = [(tool.tool_name, tool.description) for tool in all_tools]
        
        prompt = build_analyze_prompt(
            available_actions=[("speak", "è¯­éŸ³æ’­æŠ¥", ["tts"])],
            mcp_tools=mcp_tools
        )
        
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_text}
        ]
        
        response = await self.llm_client.chat_completion(
            messages=messages,
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        import json
        return json.loads(response)

    async def _call_mcp_tool(self, task_info: Dict) -> Dict[str, Any]:
        """è°ƒç”¨ MCP å·¥å…·"""
        params = task_info.get("parameters", {})
        user_intent = params.get("user_intent", "")
        context = params.get("context", {})
        
        # åˆ›å»º MCP ä»»åŠ¡
        mcp_task = UnifiedTask(
            task_type=TaskType.MCP_CALL,
            priority=7,
            timeout=60.0,
            execution_data={
                "goal": user_intent,
                "user_intent": user_intent,
                "max_steps": 5
            },
            context=context
        )
        
        # æäº¤å¹¶ç­‰å¾…
        task_id = await self.agent.submit_task(mcp_task)
        
        max_wait = 60
        waited = 0
        
        while waited < max_wait:
            task_status = await self.agent.get_task_status(task_id)
            
            if task_status == TaskStatus.COMPLETED:
                task_detail = await self.agent.get_task_detail(task_id)
                
                # ğŸ‘‡ ä¿®å¤ï¼šé˜²å¾¡æ€§å¤„ç† result ä¸º None çš„æƒ…å†µ
                if not task_detail:
                    return {"success": False, "error": "Task detail not found"}
                
                if not task_detail.result:
                    return {"success": False, "error": "Task completed but no result"}
                
                # ğŸ‘‡ ä¿®å¤ï¼šç¡®ä¿ result æ˜¯å­—å…¸
                if not isinstance(task_detail.result, dict):
                    return {
                        "success": False, 
                        "error": f"Invalid result type: {type(task_detail.result)}"
                    }
                
                return task_detail.result
            
            elif task_status == TaskStatus.FAILED:
                task_detail = await self.agent.get_task_detail(task_id)
                
                # ğŸ‘‡ ä¿®å¤ï¼šå®‰å…¨è·å–é”™è¯¯ä¿¡æ¯
                error_msg = "Unknown error"
                if task_detail and task_detail.result:
                    if isinstance(task_detail.result, dict):
                        error_msg = task_detail.result.get("error", "Unknown error")
                    else:
                        error_msg = str(task_detail.result)
                
                return {"success": False, "error": error_msg}
            
            await asyncio.sleep(1)
            waited += 1
        
        return {"success": False, "error": "Timeout"}
    
    async def _generate_final_response(self, user_text: str, mcp_result: Dict) -> str:
        """èåˆ MCP ç»“æœç”Ÿæˆå›å¤"""
        
        # ğŸ‘‡ ä¿®å¤ï¼šæ›´æ™ºèƒ½åœ°æå–å·¥å…·è¾“å‡º
        tool_output = None
        
        # å°è¯•å¤šç§è·¯å¾„è·å–å®é™…ç»“æœ
        if "final_result" in mcp_result:
            tool_output = mcp_result["final_result"]
        elif "result" in mcp_result:
            tool_output = mcp_result["result"]
        elif "step_results" in mcp_result and mcp_result["step_results"]:
            # å¦‚æœæœ‰æ­¥éª¤ç»“æœï¼Œå–æœ€åä¸€ä¸ª
            last_step = mcp_result["step_results"][-1]
            tool_output = last_step.get("result")
        
        # å¦‚æœ tool_output æ˜¯åµŒå¥—å­—å…¸ï¼Œç»§ç»­æå–
        if isinstance(tool_output, dict):
            if "result" in tool_output:
                tool_output = tool_output["result"]
            elif "content" in tool_output:
                tool_output = tool_output["content"]
        
        # æ ¼å¼åŒ–è¾“å‡ºï¼ˆå¤„ç†åˆ—è¡¨ã€å­—å…¸ç­‰ï¼‰
        if isinstance(tool_output, list):
            # å¦‚æœæ˜¯æœç´¢ç»“æœåˆ—è¡¨
            if tool_output and isinstance(tool_output[0], dict):
                # æå–å…³é”®ä¿¡æ¯ï¼ˆå¦‚æ ‡é¢˜ã€æ‘˜è¦ï¼‰
                formatted_output = []
                for i, item in enumerate(tool_output[:3], 1):  # åªå–å‰3æ¡
                    if "title" in item:
                        formatted_output.append(f"{i}. {item.get('title', '')} - {item.get('snippet', '')[:100]}")
                    else:
                        formatted_output.append(f"{i}. {str(item)[:100]}")
                tool_output = "\n".join(formatted_output)
            else:
                tool_output = "\n".join(str(item) for item in tool_output[:5])
        elif isinstance(tool_output, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå– query å’Œ results
            if "query" in tool_output and "results" in tool_output:
                results = tool_output["results"]
                if results:
                    formatted_results = []
                    for i, r in enumerate(results[:3], 1):
                        title = r.get("title", "")
                        snippet = r.get("snippet", "")
                        formatted_results.append(f"{i}. {title}\n   {snippet[:150]}")
                    tool_output = "\n\n".join(formatted_results)
                else:
                    tool_output = "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

    ç”¨æˆ·é—®é¢˜ï¼š"{user_text}"

    å·¥å…·è¿”å›çš„ä¿¡æ¯ï¼š
    {tool_output}

    è¯·ç”¨ç®€æ´ã€è‡ªç„¶ã€å£è¯­åŒ–çš„ä¸­æ–‡å›å¤ç”¨æˆ·ï¼ˆ2-3å¥è¯ï¼Œæ€»ç»“å…³é”®ä¿¡æ¯ï¼‰ã€‚
    å¦‚æœæ˜¯æ–°é—»æˆ–æœç´¢ç»“æœï¼Œç®€è¦æ¦‚æ‹¬å‰å‡ æ¡å³å¯ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_text}
        ]
        
        response = await self.llm_client.chat_completion(
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )
        
        return response
    
    async def _speak(self, text: str) -> bool:
        """æ’­æŠ¥è¯­éŸ³"""
        result = await self.agent.execute_action("speak", input_data=text)
        return result.success